{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login to Docker Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Docker Registry\n",
    "!gcloud auth configure-docker --quiet\n",
    "\n",
    "# Create a /tmp directory (needed in next steps)\n",
    "!mkdir -p /tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Dependencies (Used by Fairing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn pandas xgboost fairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from xgboost import XGBRegressor\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "TRAINING_URL=\"https://raw.githubusercontent.com/kubeflow/examples/master/xgboost_ames_housing/ames_dataset/train.csv\"\n",
    "TRAINING_FILE=\"train.csv\"\n",
    "\n",
    "ESTIMATORS=1000\n",
    "LEARNING_RATE=0.1\n",
    "TEST_FRACTION_SIZE=0.25\n",
    "EARLY_STOPPING_ROUNDS=50\n",
    "\n",
    "def run_training_and_eval():\n",
    "    (train_X, train_y), (test_X, test_y) = read_input()\n",
    "    model = train_model(train_X,\n",
    "                        train_y,\n",
    "                        test_X,\n",
    "                        test_y,\n",
    "                        ESTIMATORS,\n",
    "                        LEARNING_RATE)\n",
    "\n",
    "    eval_model(model, test_X, test_y)\n",
    "\n",
    "def download(url, file_name):\n",
    "    with urllib.request.urlopen(url) as response, open(file_name, \"wb\") as file:\n",
    "        file.write(response.read())\n",
    "\n",
    "def read_input(test_size=TEST_FRACTION_SIZE):\n",
    "    \"\"\"Read input data and split it into train and test.\"\"\"\n",
    "    download(TRAINING_URL, TRAINING_FILE)\n",
    "    data = pd.read_csv(TRAINING_FILE)\n",
    "    data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "\n",
    "    y = data.SalePrice\n",
    "    X = data.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object'])\n",
    "\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X.values,\n",
    "                                                        y.values,\n",
    "                                                        test_size=test_size,\n",
    "                                                        shuffle=False)\n",
    "\n",
    "    imputer = Imputer()\n",
    "    train_X = imputer.fit_transform(train_X)\n",
    "    test_X = imputer.transform(test_X)\n",
    "\n",
    "    return (train_X, train_y), (test_X, test_y)\n",
    "\n",
    "def train_model(train_X,\n",
    "                train_y,\n",
    "                test_X,\n",
    "                test_y,\n",
    "                n_estimators,\n",
    "                learning_rate):\n",
    "    \"\"\"Train the model using XGBRegressor.\"\"\"\n",
    "    model = XGBRegressor(n_estimators=n_estimators,\n",
    "                      learning_rate=learning_rate)\n",
    "\n",
    "    model.fit(train_X,\n",
    "              train_y,\n",
    "              early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "              eval_set=[(test_X, test_y)])\n",
    "\n",
    "    logging.info(\"Best RMSE on eval: %.2f with %d rounds\",\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1)\n",
    "    return model\n",
    "\n",
    "def eval_model(model, test_X, test_y):\n",
    "    \"\"\"Evaluate the model performance.\"\"\"\n",
    "    predictions = model.predict(test_X)\n",
    "    logging.info(\"mean_absolute_error=%.2f\", mean_absolute_error(predictions, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fairing\n",
    "\n",
    "DOCKER_REGISTRY = 'gcr.io/pipelineai2/fairing-jobs'\n",
    "\n",
    "fairing.config.set_builder('append',  \n",
    "                           registry=DOCKER_REGISTRY, \n",
    "                           push=True)\n",
    "fairing.config.set_deployer('job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fairing\n",
    "\n",
    "train = fairing.config.fn(run_training_and_eval)\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
